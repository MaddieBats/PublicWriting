```
/|\ ^._.^ /|\
```

It is an hour past sunset, a kilometre into some old-growth parcel of some middle-land, mid-June, mixed-use deciduous forest. The last human left for her bed and breakfast a couple of hours ago, the remnants of her whistle-stop tour being three willow canes, each holding a sharpied junction box containing a small, rectangular circuit board and three AA batteries, a micro-SD card, a switch set to “CUSTOM”, a pulsating red LED and a microphone facing up and through the junction box towards the canopy above. These three acoustic monitors have been placed with careful intentions (albeit with the contingency of any ecological experiment) to capture a sliver of the ultrasonic vibrational spectrum: a sample of nocturnal high-frequency resonances, some communicative, some incidental, some interactive, some in absence. Whilst she is eating a lamb bhuna in the nearest village and the monitor is whirring at an infernal-to-ants 48Hz near-constantly I am in my mouse-infested house of multiple occupancy in North East London where there are surprsingly quiute a few bats feeling a similarly infernal whir of cortisol at the fear that I forgot to place the 8kHz high pass filter to make sure no one hears the teenagers smoking weed in the background of our ultrasonic spatial capture matrix.

The monitor, an AudioMoth made by Open Acoustics, is repeatedly storing data about the pressure of the air around it into its digital buffer and !CRASH! when the sound is interpreted to be vibrational above some pre-agreed threshold it starts to (384 thousand times a second!) encode a two channel 16-bit .WAV file onto a microSD card. It waited until the right frequency was detectable and then it started writing zeros and ones and I think I want to believe that the machine was doing something like listening.

About five nights pass and those five nights happen a thousand times all over the country scattered over the bat maternity season and I maybe visit two forests in that time and play around with a heterodyne detector or some frequency-dividing handheld monitor and I like to think I’m listening too, when a Lesser Horseshoe squeaks an order of magnitude higher in pitch than what my ears are sensitive to these days. That’s just as mediated as my little passive acoustic rectangles though, if not moreso. With a heterodyne it subtracts some inner hum from the ‘real’ and plays me a subtracted indication of noise, and frequency division digitally encodes into a buffer and spits out a transformed version of the sound. I’m listening in the sense that I’m using my ears but my ears aren’t those of a bat and I don’t have a clue what affective register the mother in this roost is holding onto as she flutters above my head in the red glow of my head torch. But something tells me that because I’m there and I can feel her wings beating the air around me, because there’s a felt percussiveness to the vibration in the room, that it’s somehow more real. I’m really really listening to a real life bat, not some recording, even if it is modulated by a prosthetic.

Those thousands of five nights eventually filter in through the postal service to the desks of my colleagues and I and we filter them and clean them and move the encoded bits from the SD to a hard drive and then up and up into my carefully organised folder structure using pre-agreed and forked github repositories and S3 access keys. On upload to the cloud a notification is triggered in the AWS architecture to start a job on some distributed server in a warehouse somewhere cold and dark and lifeless. This triggered action is not dissimilar to the listening for a certain frequency our little recorder did months ago. And that triggered action cascades a bidding war for time on the EC2 instance to do work, to do digital labour. Once the price is agreed upon a convolutional neural network pours over that .WAV file, pauses somewhere in the middle, and draws a bounding box over what it might be said to be: ‘listened-to-bat-sounds’. It detects and classifies in an instant and reports its findings in a database. One project might yield thirty million rows of possible bat calls, a hundred terabytes of bat sounds, containerised computing power estimating identity of caller in a week that which would take experts hundreds of years. 

And months pass and we keep on uploading and our architecture keeps categorising and adding new rows to our database and at some point I will decide to drag out the tabularised representation of it. No one used to believe that weather predictions were useful unless there was a human in the loop, unless some poor sailor in the North Sea was able to stick her thumb up to the wind and feel the gale. We’re somewhere similar with our bat algorithm, no one trusts us until an expert listens to at least some of it first. So it’s only now that after some stratification and downloading and snipping and sending off those snippets to our experts that anyone bothers to do what we might conventionally call “hearing” of our bats. Often this “hearing” is in a time-stretched aural play through headphones of the file, but more regularly it is in the form of a visual assessment of the spectrogram. We might check 400 files ourselves out of 30 million. Which ones get checked are based on interest and curiosity and systematic necessity.

As soon as they are checked, the files are archived and will probably never be looked at again. This information is only really explored in aggregate, and we've worked hard to prove to those in the biological records keeping community that a machine-driven probabilistic assessment of the presence or actvity based on machine-interpollated prosthetic detection deserves to be recorded in perpetuity. It's amazing how often the experts get it wrong anyway. We didn't even know Soprano and Common Pipistrelles were different species until a couple years ago. It's all probablistic, it's all mediated. We like to pretend that we have an emotional connection to the individual bats flying over our heads in the night but in the dark it's all just chirps on a speaker. We don’t care about that sort of thing, anyway.

Almost every sound is made by a bat to another bat, and while that happens, some of our lonely machines note a couple of million bits, those bits are assessed and categorised by another lonely machine, and then that assessment is stored in the cloud away from prying eyes and ears. An alien species talking to machines and machines and I'm there, clicking things through, occassionally peeking in, but to what? To rows on a database in my heated office while I drink miso soup and steal time to learn python?

I think I listened to a bat this year but I can’t be sure. 
